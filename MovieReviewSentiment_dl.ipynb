{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "MovieReviewSentiment_dl.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "14e09GOdk-Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from string import punctuation\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Dropout,Embedding,Flatten\n",
        "from keras.models import load_model\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "lemma = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztV3zwNiERju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXaBMj04HxJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_columns=99\n",
        "pd.options.display.max_colwidth=300\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMMYVpcak-G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(r'https://raw.githubusercontent.com/subhajitchoudhury/files/master/train.tsv',sep='\\t')\n",
        "testdf = pd.read_csv(r'https://raw.githubusercontent.com/subhajitchoudhury/files/master/test.tsv',sep='\\t')            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scT6FHJjk-HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shxaaq8pk-HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.loc[df.groupby('SentenceId')['PhraseId'].idxmin()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTg4Pl2Ok-HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.groupby('SentenceId')['PhraseId'].count().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuE7FYRXk-HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "def cleantext(data):\n",
        "    cleantextlist = []\n",
        "    for text in data:\n",
        "        text=re.sub('[^a-zA-Z]',' ',text)\n",
        "        #text = \" \".join([stemmer.stem(w) for w in word_tokenize(text.lower())])\n",
        "        text = \" \".join([lemma.lemmatize(w) for w in word_tokenize(text.lower())])\n",
        "        cleantextlist.append(text)\n",
        "    return cleantextlist\n",
        "df['cleanPhrase'] = cleantext(df['Phrase'])\n",
        "testdf['cleanPhrase'] = cleantext(testdf['Phrase'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak3OtF4lk-Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = df.cleanPhrase.values\n",
        "test_text = testdf.cleanPhrase.values\n",
        "y = to_categorical(df.Sentiment)\n",
        "num_classes = y.shape[1]\n",
        "print(\"{},{},{},{}\".format(train_text.shape,test_text.shape,y.shape,num_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur3pngaPk-Hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(train_text,y,test_size=0.3,stratify=y)\n",
        "print(\"{},{},{}\".format(x_train.shape,x_val.shape,y_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRThICg0k-Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alltext = \" \".join(x_train)\n",
        "unique_words = len(set(word_tokenize(alltext)))\n",
        "len_reviews = [len(word_tokenize(x)) for x in x_train]\n",
        "maxlen = max(len_reviews)\n",
        "print(\"{} : {}\".format(unique_words,maxlen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlkRi3Bk-H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=unique_words)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train_tok = tokenizer.texts_to_sequences(x_train)\n",
        "x_val_tok = tokenizer.texts_to_sequences(x_val)\n",
        "x_test_tok = tokenizer.texts_to_sequences(test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdDeM7Ndk-IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pad = sequence.pad_sequences(x_train_tok,maxlen=maxlen)\n",
        "x_val_pad = sequence.pad_sequences(x_val_tok,maxlen=maxlen)\n",
        "x_test_pad = sequence.pad_sequences(x_test_tok,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgXO4Ha9k-IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model1 = Sequential()\n",
        "# model1.add(Embedding(unique_words,100,mask_zero=True))\n",
        "# model1.add(LSTM(64,dropout=0.4,recurrent_dropout=0.4,return_sequences=True))\n",
        "# model1.add(LSTM(32,dropout=0.4,recurrent_dropout=0.4,return_sequences=False))\n",
        "# model1.add(Dense(num_classes,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhANpY-ck-IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaAv71NAk-IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# history1 = model1.fit(x_train_pad,y_train,validation_data=(x_val_pad,y_val),batch_size=128,epochs=5,verbose=1)\n",
        "# model1.save('model3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uZCtb2RqSHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model2.save('model2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeLmOW9IqpOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1=load_model('model3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxrbq01lCmML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "#y_pred1=model1.predict_classes(x_test_pad,verbose=1)\n",
        "y_val_pred = model1.predict_classes(x_val_pad,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-QKSOgCCqTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sub=pd.read_csv(r'https://raw.githubusercontent.com/subhajitchoudhury/files/master/sampleSubmission.csv')\n",
        "# sub.Sentiment=y_pred1\n",
        "# sub.to_csv('submissionfile.csv',index=False)\n",
        "# sub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxWdGAk27oMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sub['Phrase'] = testdf.Phrase\n",
        "# print(sub.Sentiment.value_counts())\n",
        "# print(df.Sentiment.value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaYOHEssWDpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewtext = [\"this movie was bad.\",\"this movie was good\",\"the movie was the worst MOVIE I have seen\",\"beautiful movie!\"]\n",
        "ctext = cleantext(reviewtext)\n",
        "ttext = tokenizer.texts_to_sequences(ctext)\n",
        "ptext = sequence.pad_sequences(ttext,maxlen=maxlen)\n",
        "#print(ptext)\n",
        "print(model1.predict_classes(ptext))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0JPrSCbom2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.Sentiment==0][['cleanPhrase','Sentiment']][:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKeoWWjBHUSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame(df.loc[df.groupby('SentenceId')['PhraseId'].idxmin()][['cleanPhrase','Sentiment']])\n",
        "df2[df2.Sentiment==4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cZU33a1VedK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.DataFrame(y_val_pred, columns=['y_pred'])\n",
        "df1['y_val'] = list(y_val)\n",
        "df1['text'] = list(x_val)\n",
        "df1['y_val1'] = [x.argmax() for x in df1.y_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKBC7RvDVxxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1[df1.y_pred!=df1.y_val1][['y_pred','y_val1','text',]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efwPdcH55GUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import sleep\n",
        "for i in range(1,1000):\n",
        "  sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}